{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ohKPavP3by0T"
   },
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 781,
     "status": "ok",
     "timestamp": 1733848796472,
     "user": {
      "displayName": "Rhys Wickens",
      "userId": "08020993139237173533"
     },
     "user_tz": 420
    },
    "id": "AtrQ1lmcKbNH",
    "outputId": "a957d15c-7342-44a9-96d1-091411ca328f"
   },
   "outputs": [],
   "source": [
    "# def setup_environment():\n",
    "#   try:\n",
    "#       # Check if running in Google Colab\n",
    "#       import google.colab\n",
    "#       from google.colab import drive\n",
    "#       drive.mount('/content/drive')\n",
    "#       folder_path = 'drive/MyDrive/ENSF612Project'\n",
    "#       print(\"Running in Google Colab. Folder path:\", folder_path)\n",
    "#   except ImportError:\n",
    "#       folder_path = '.'\n",
    "#       print(\"Running locally: Folder path:\", folder_path)\n",
    "#   return folder_path\n",
    "\n",
    "# folder_path = setup_environment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JnHHHuYxKfsd"
   },
   "source": [
    "Check that `train.csv` and `test.csv` are visible in the given environment (Note that if running locally, these files must be in the same directory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 447,
     "status": "ok",
     "timestamp": 1733847648152,
     "user": {
      "displayName": "Rhys Wickens",
      "userId": "08020993139237173533"
     },
     "user_tz": 420
    },
    "id": "fuAF7_jNKfBq",
    "outputId": "e918f86a-9010-497f-c1e2-8ab0d286ed61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AirlineDelays.ipynb\t  AirlineDelays_Ryan.ipynb  test.csv\n",
      "AirlineDelays_Rhys.ipynb  AirlineDelays_Tom.ipynb   train.csv\n"
     ]
    }
   ],
   "source": [
    "# !ls drive/MyDrive/ENSF612Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16831,
     "status": "ok",
     "timestamp": 1733847666451,
     "user": {
      "displayName": "Rhys Wickens",
      "userId": "08020993139237173533"
     },
     "user_tz": 420
    },
    "id": "BFYA5gU48eCv",
    "outputId": "01611179-096c-4459-e9eb-ce498a55782d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.3)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
     ]
    }
   ],
   "source": [
    "# !apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
    "# !pip install pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S2QsPyOScUAm"
   },
   "source": [
    "## Spark Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 128,
     "status": "ok",
     "timestamp": 1733848842428,
     "user": {
      "displayName": "Rhys Wickens",
      "userId": "08020993139237173533"
     },
     "user_tz": 420
    },
    "id": "wO_4XAGwJ4pY"
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "def initialize_spark():\n",
    "    spark = SparkSession.builder \\\n",
    "        .config(\"spark.executor.memory\", \"8g\") \\\n",
    "        .config(\"spark.driver.memory\", \"8g\") \\\n",
    "        .config(\"spark.driver.host\", \"127.0.0.1\") \\\n",
    "        .config(\"spark.driver.port\", \"5001\") \\\n",
    "        .getOrCreate()\n",
    "    sc = spark.sparkContext\n",
    "    sc.setLogLevel(\"WARN\")\n",
    "    return spark\n",
    "\n",
    "spark = initialize_spark()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0XgzVDcrcewh"
   },
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 87138,
     "status": "ok",
     "timestamp": 1733849094707,
     "user": {
      "displayName": "Rhys Wickens",
      "userId": "08020993139237173533"
     },
     "user_tz": 420
    },
    "id": "g_HAJHqkcd1J"
   },
   "outputs": [],
   "source": [
    "folder_path = '.'\n",
    "\n",
    "def load_data(spark, folder_path, train_file=\"train.csv\", test_file=\"test.csv\"):\n",
    "  train_df = spark.read.csv(f\"{folder_path}/{train_file}\", header=True, inferSchema=True)\n",
    "  test_df = spark.read.csv(f\"{folder_path}/{test_file}\", header=True, inferSchema=True)\n",
    "  return train_df, test_df\n",
    "\n",
    "train_df, test_df = load_data(spark, folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ElvEmAsdeY7"
   },
   "source": [
    "## Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 131833,
     "status": "ok",
     "timestamp": 1733849291279,
     "user": {
      "displayName": "Rhys Wickens",
      "userId": "08020993139237173533"
     },
     "user_tz": 420
    },
    "id": "4McuHNPudgc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+\n",
      "|label|  count|\n",
      "+-----+-------+\n",
      "|  0.0|3683185|\n",
      "|  1.0| 859158|\n",
      "+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, StandardScaler\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "def preprocess_data(train_df, test_df, target_column, numeric_features, string_features):\n",
    "    # Define stages\n",
    "    string_indexers = [StringIndexer(inputCol=col, outputCol=f\"{col}_index\") for col in string_features]\n",
    "    one_hot_encoders = [OneHotEncoder(inputCol=f\"{col}_index\", outputCol=f\"{col}_one_hot\") for col in string_features]\n",
    "    numeric_assembler = VectorAssembler(inputCols=numeric_features, outputCol=\"numeric_features\")\n",
    "    scaler = StandardScaler(inputCol=\"numeric_features\", outputCol=\"numeric_features_scaled\", withMean=True, withStd=True)\n",
    "    label_indexer = StringIndexer(inputCol=target_column, outputCol=\"label\")\n",
    "\n",
    "    # Pipeline\n",
    "    stages = string_indexers + one_hot_encoders + [numeric_assembler, scaler, label_indexer]\n",
    "    pipeline = Pipeline(stages=stages)\n",
    "\n",
    "    # Fit and transform\n",
    "    pipeline_model = pipeline.fit(train_df)\n",
    "    train_transformed = pipeline_model.transform(train_df)\n",
    "    test_transformed = pipeline_model.transform(test_df)\n",
    "    return train_transformed, test_transformed\n",
    "\n",
    "numeric_features = [\n",
    "    \"MONTH\",\n",
    "    \"DAY_OF_WEEK\",\n",
    "    \"DISTANCE_GROUP\",\n",
    "    \"SEGMENT_NUMBER\",\n",
    "    \"CONCURRENT_FLIGHTS\",\n",
    "    \"NUMBER_OF_SEATS\",\n",
    "    \"AIRPORT_FLIGHTS_MONTH\",\n",
    "    \"AIRLINE_AIRPORT_FLIGHTS_MONTH\",\n",
    "    \"AVG_MONTHLY_PASS_AIRPORT\",\n",
    "    \"AVG_MONTHLY_PASS_AIRLINE\",\n",
    "    \"FLT_ATTENDANTS_PER_PASS\",\n",
    "    \"GROUND_SERV_PER_PASS\",\n",
    "    \"PLANE_AGE\",\n",
    "    \"LATITUDE\",\n",
    "    \"LONGITUDE\",\n",
    "    \"PRCP\",\n",
    "    \"SNOW\",\n",
    "    \"SNWD\",\n",
    "    \"TMAX\",\n",
    "    \"AWND\",\n",
    "    \"CARRIER_HISTORICAL\",\n",
    "    \"DEP_AIRPORT_HIST\",\n",
    "    \"DAY_HISTORICAL\",\n",
    "    \"DEP_BLOCK_HIST\"\n",
    "]\n",
    "string_features = [\n",
    "    'DEP_TIME_BLK',\n",
    "    'CARRIER_NAME',\n",
    "    'DEPARTING_AIRPORT',\n",
    "    'PREVIOUS_AIRPORT'\n",
    "]\n",
    "train_transformed, test_transformed = preprocess_data(train_df, test_df, \"DEP_DEL15\", numeric_features, string_features)\n",
    "train_transformed.groupBy(\"label\").count().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s6DSONQYds2P"
   },
   "source": [
    "## Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating LogisticRegression...\n",
      "Train Accuracy: 0.8110, Test Accuracy: 0.8110\n",
      "Evaluating RandomForestClassifier...\n",
      "Train Accuracy: 0.8109, Test Accuracy: 0.8109\n",
      "Evaluating MultilayerPerceptronClassifier...\n",
      "Train Accuracy: 0.8131, Test Accuracy: 0.8129\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, MultilayerPerceptronClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "def train_and_evaluate(train_data, test_data, classifier, feature_col=\"numeric_features_scaled\"):\n",
    "    # Add classifier to pipeline\n",
    "    classifier.setFeaturesCol(feature_col).setLabelCol(\"label\")\n",
    "    pipeline = Pipeline(stages=[classifier])\n",
    "    model = pipeline.fit(train_data)\n",
    "\n",
    "    # Predictions\n",
    "    train_predictions = model.transform(train_data)\n",
    "    test_predictions = model.transform(test_data)\n",
    "\n",
    "    # Evaluation\n",
    "    evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "    train_accuracy = evaluator.evaluate(train_predictions)\n",
    "    test_accuracy = evaluator.evaluate(test_predictions)\n",
    "\n",
    "    print(f\"Train Accuracy: {train_accuracy:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
    "    return model, train_predictions, test_predictions\n",
    "\n",
    "# Example: Logistic Regression, Random Forest, and Multilayer Perceptron\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.1)\n",
    "rf = RandomForestClassifier(numTrees=100)\n",
    "mlp = MultilayerPerceptronClassifier(layers=[len(numeric_features), 10, 2])  # Example layer sizes\n",
    "\n",
    "# Store predictions for all classifiers\n",
    "predictions = {}\n",
    "for classifier in [lr, rf, mlp]:\n",
    "    model_name = classifier.__class__.__name__\n",
    "    print(f\"Evaluating {model_name}...\")\n",
    "    model, train_preds, test_preds = train_and_evaluate(train_transformed, test_transformed, classifier)\n",
    "    predictions[model_name] = {\"train\": train_preds, \"test\": test_preds, \"model\": model}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oc1TRgwNkNxY"
   },
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 193344,
     "status": "ok",
     "timestamp": 1733852625569,
     "user": {
      "displayName": "Rhys Wickens",
      "userId": "08020993139237173533"
     },
     "user_tz": 420
    },
    "id": "kaQXhzctkRwp",
    "outputId": "4c7acc3e-ad74-445f-9122-d0e107d40bcc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for LogisticRegression on Test Data:\n",
      "Confusion Matrix:\n",
      "TP: 1341, FP: 1094\n",
      "FN: 366869, TN: 1577415\n",
      "Precision: 0.5507\n",
      "Recall: 0.0036\n",
      "F1 Score: 0.0072\n",
      "----------------------------------------\n",
      "Metrics for RandomForestClassifier on Test Data:\n",
      "Confusion Matrix:\n",
      "TP: 0, FP: 0\n",
      "FN: 368210, TN: 1578509\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "----------------------------------------\n",
      "Metrics for MultilayerPerceptronClassifier on Test Data:\n",
      "Confusion Matrix:\n",
      "TP: 14032, FP: 10021\n",
      "FN: 354178, TN: 1568488\n",
      "Precision: 0.5834\n",
      "Recall: 0.0381\n",
      "F1 Score: 0.0715\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "def compute_metrics(predictions, label_col=\"label\", prediction_col=\"prediction\", positive_class=1):\n",
    "    # Create confusion matrix components\n",
    "    tp = predictions.filter((F.col(label_col) == positive_class) & (F.col(prediction_col) == positive_class)).count()\n",
    "    tn = predictions.filter((F.col(label_col) != positive_class) & (F.col(prediction_col) != positive_class)).count()\n",
    "    fp = predictions.filter((F.col(label_col) != positive_class) & (F.col(prediction_col) == positive_class)).count()\n",
    "    fn = predictions.filter((F.col(label_col) == positive_class) & (F.col(prediction_col) != positive_class)).count()\n",
    "\n",
    "    # Confusion matrix\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(f\"TP: {tp}, FP: {fp}\")\n",
    "    print(f\"FN: {fn}, TN: {tn}\")\n",
    "\n",
    "    # Precision, Recall, and F1 Score\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1_score:.4f}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "# Iterate through all classifiers and calculate metrics\n",
    "for name, preds in predictions.items():\n",
    "    print(f\"Metrics for {name} on Test Data:\")\n",
    "    compute_metrics(preds[\"test\"], label_col=\"label\", prediction_col=\"prediction\", positive_class=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.8109, Test Accuracy: 0.8109\n",
      "Confusion Matrix:\n",
      "TP: 0, FP: 0\n",
      "FN: 368210, TN: 1578509\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "lr2 = LogisticRegression(maxIter=10, regParam=1)\n",
    "\n",
    "model_lr2, train_preds_lr2, test_preds_lr2 = train_and_evaluate(train_transformed, test_transformed, lr2)\n",
    "compute_metrics(test_preds_lr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.8114, Test Accuracy: 0.8114\n",
      "Confusion Matrix:\n",
      "TP: 5973, FP: 5001\n",
      "FN: 362237, TN: 1573508\n",
      "Precision: 0.5443\n",
      "Recall: 0.0162\n",
      "F1 Score: 0.0315\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "lr3 = LogisticRegression(maxIter=10, regParam=0.01)\n",
    "\n",
    "model_lr3, train_preds_lr3, test_preds_lr3 = train_and_evaluate(train_transformed, test_transformed, lr3)\n",
    "compute_metrics(test_preds_lr3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.8113, Test Accuracy: 0.8113\n",
      "Confusion Matrix:\n",
      "TP: 7365, FP: 6439\n",
      "FN: 360845, TN: 1572070\n",
      "Precision: 0.5335\n",
      "Recall: 0.0200\n",
      "F1 Score: 0.0386\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "lr4 = LogisticRegression(maxIter=1000, regParam=0.001)\n",
    "\n",
    "model_lr4, train_preds_lr4, test_preds_lr4 = train_and_evaluate(train_transformed, test_transformed, lr4)\n",
    "compute_metrics(test_preds_lr4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.8151, Test Accuracy: 0.8150\n",
      "Confusion Matrix:\n",
      "TP: 24917, FP: 16834\n",
      "FN: 343293, TN: 1561675\n",
      "Precision: 0.5968\n",
      "Recall: 0.0677\n",
      "F1 Score: 0.1216\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mlp2 = MultilayerPerceptronClassifier(\n",
    "    layers=[len(numeric_features), 50, 20, 2],  # Larger architecture\n",
    "    maxIter=200,                               # More iterations\n",
    "    stepSize=0.01,                             # Smaller learning rate\n",
    ")\n",
    "\n",
    "mlp2, train_preds_mlp2, test_preds_mlp2 = train_and_evaluate(train_transformed, test_transformed, mlp2)\n",
    "compute_metrics(test_preds_mlp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.6022, Test Accuracy: 0.6025\n",
      "Confusion Matrix:\n",
      "TP: 242471, FP: 648045\n",
      "FN: 125739, TN: 930464\n",
      "Precision: 0.2723\n",
      "Recall: 0.6585\n",
      "F1 Score: 0.3853\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when, col\n",
    "\n",
    "# Calculate weights for the classes\n",
    "class_counts = train_transformed.groupBy(\"label\").count().collect()\n",
    "majority_class_count = max(row[\"count\"] for row in class_counts)\n",
    "weights = {row[\"label\"]: majority_class_count / row[\"count\"] for row in class_counts}\n",
    "print(weights)\n",
    "\n",
    "# Add weight column to the training data\n",
    "train_data_weighted = train_transformed.withColumn(\"weight\", when(col(\"label\") == 1, weights[1]).otherwise(weights[0]))\n",
    "\n",
    "# Use the weight column in the RandomForestClassifier\n",
    "rf2 = RandomForestClassifier(numTrees=100, weightCol=\"weight\")\n",
    "\n",
    "# Train and evaluate\n",
    "model_rf2, train_preds_rf2, test_preds_rf2 = train_and_evaluate(train_data_weighted, test_transformed, rf2)\n",
    "compute_metrics(test_preds_rf2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.8115, Test Accuracy: 0.8114\n",
      "Confusion Matrix:\n",
      "TP: 16978, FP: 15858\n",
      "FN: 351232, TN: 1562651\n",
      "Precision: 0.5171\n",
      "Recall: 0.0461\n",
      "F1 Score: 0.0847\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "weights = {0: 1.0, 1: 2.0}  # Adjust weights to prioritize recall while maintaining precision\n",
    "\n",
    "train_data_weighted = train_transformed.withColumn(\n",
    "    \"weight\", when(col(\"label\") == 1, weights[1]).otherwise(weights[0])\n",
    ")\n",
    "\n",
    "# Use the weight column in the RandomForestClassifier\n",
    "rf3 = RandomForestClassifier(numTrees=100, weightCol=\"weight\")\n",
    "\n",
    "# Train and evaluate\n",
    "model_rf3, train_preds_rf3, test_preds_rf3 = train_and_evaluate(train_data_weighted, test_transformed, rf3)\n",
    "compute_metrics(test_preds_rf3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.7642, Test Accuracy: 0.7643\n",
      "Confusion Matrix:\n",
      "TP: 117255, FP: 207849\n",
      "FN: 250955, TN: 1370660\n",
      "Precision: 0.3607\n",
      "Recall: 0.3184\n",
      "F1 Score: 0.3382\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "weights = {0: 1, 1: 3.0}  # Adjust weights to prioritize recall while maintaining precision\n",
    "\n",
    "train_data_weighted = train_transformed.withColumn(\n",
    "    \"weight\", when(col(\"label\") == 1, weights[1]).otherwise(weights[0])\n",
    ")\n",
    "\n",
    "# Use the weight column in the RandomForestClassifier\n",
    "rf3 = RandomForestClassifier(numTrees=100, weightCol=\"weight\")\n",
    "\n",
    "# Train and evaluate\n",
    "model_rf3, train_preds_rf3, test_preds_rf3 = train_and_evaluate(train_data_weighted, test_transformed, rf3)\n",
    "compute_metrics(test_preds_rf3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_importances = model_rf2.stages[-1].featureImportances\n",
    "\n",
    "# # Example list of feature names\n",
    "# feature_names = numeric_features  # Replace with your actual feature names list\n",
    "\n",
    "# # Pair feature names with their importance\n",
    "# feature_importance_dict = list(zip(feature_names, feature_importances))\n",
    "\n",
    "# # Sort by importance (descending order)\n",
    "# sorted_features = sorted(feature_importance_dict, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# # Display\n",
    "# for feature, importance in sorted_features:\n",
    "#     print(f\"{feature}: {importance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights = {0: 1, 1: 3.0}  # Adjust weights to prioritize recall while maintaining precision\n",
    "\n",
    "# train_data_weighted = train_transformed.withColumn(\n",
    "#     \"weight\", when(col(\"label\") == 1, weights[1]).otherwise(weights[0])\n",
    "# )\n",
    "\n",
    "# # Use the weight column in the RandomForestClassifier\n",
    "# rf3 = RandomForestClassifier(numTrees=100, maxDepth=15, featureSubsetStrategy=\"log2\", weightCol=\"weight\")\n",
    "\n",
    "# # Train and evaluate\n",
    "# model_rf3, train_preds_rf3, test_preds_rf3 = train_and_evaluate(train_data_weighted, test_transformed, rf3)\n",
    "# compute_metrics(test_preds_rf3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances: (24,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23],[0.00726192894817795,7.526633913836861e-06,0.0013252201264470306,0.1408248726182614,0.0005140923495601671,0.001886059607902475,0.008961957578488925,0.0029865012800210137,0.01065021071670124,0.00633479615951054,0.0009471899032163822,0.0034032137424054787,5.073691264169398e-05,0.0011015660817078592,0.006071318991498746,0.09160603317605988,0.010120877893139195,0.0023196219112178165,0.002410508513319663,0.010320451194332805,0.1060649133649306,0.1126062250872355,0.04459375420778605,0.42763042300152415])\n"
     ]
    }
   ],
   "source": [
    "feature_importances = model_rf2.stages[-1].featureImportances\n",
    "print(\"Feature Importances:\", feature_importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "def cross_validate_and_evaluate(train_data, test_data, classifier, param_grid, evaluator, feature_col=\"numeric_features_scaled\"):\n",
    "    # Set up pipeline for each classifier\n",
    "    classifier.setFeaturesCol(feature_col).setLabelCol(\"label\")\n",
    "    pipeline = Pipeline(stages=[classifier])\n",
    "\n",
    "    # Cross-validation setup\n",
    "    crossval = CrossValidator(estimator=pipeline,\n",
    "                              estimatorParamMaps=param_grid,\n",
    "                              evaluator=evaluator,\n",
    "                              numFolds=5)  # 5-fold cross-validation\n",
    "\n",
    "    # Fit the model\n",
    "    cv_model = crossval.fit(train_data)\n",
    "\n",
    "    # Best model from cross-validation\n",
    "    best_model = cv_model.bestModel\n",
    "\n",
    "    # Get best parameters\n",
    "    best_params = {param.name: best_model._java_obj.getParam(param.name).json() for param in best_model.params}\n",
    "\n",
    "    # Get predictions\n",
    "    train_predictions = best_model.transform(train_data)\n",
    "    test_predictions = best_model.transform(test_data)\n",
    "\n",
    "    # Evaluate the model\n",
    "    train_accuracy = evaluator.evaluate(train_predictions)\n",
    "    test_accuracy = evaluator.evaluate(test_predictions)\n",
    "\n",
    "    # Extract prediction and label columns for metrics\n",
    "    train_labels_and_preds = train_predictions.select(\"label\", \"prediction\").rdd\n",
    "    test_labels_and_preds = test_predictions.select(\"label\", \"prediction\").rdd\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    train_metrics = MulticlassMetrics(train_labels_and_preds)\n",
    "    test_metrics = MulticlassMetrics(test_labels_and_preds)\n",
    "\n",
    "    # Get confusion matrix\n",
    "    train_conf_matrix = train_metrics.confusionMatrix().toArray()\n",
    "    test_conf_matrix = test_metrics.confusionMatrix().toArray()\n",
    "\n",
    "    # Get precision, recall, and F1 score\n",
    "    train_precision = train_metrics.precision()\n",
    "    test_precision = test_metrics.precision()\n",
    "    \n",
    "    train_recall = train_metrics.recall()\n",
    "    test_recall = test_metrics.recall()\n",
    "    \n",
    "    train_f1 = train_metrics.fMeasure()\n",
    "    test_f1 = test_metrics.fMeasure()\n",
    "\n",
    "    # Print results\n",
    "    print(f\"{classifier.__class__.__name__} - Best Parameters: {best_params}\")\n",
    "    print(f\"{classifier.__class__.__name__} - Train Accuracy: {train_accuracy:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print(f\"{classifier.__class__.__name__} - Train Precision: {train_precision:.4f}, Test Precision: {test_precision:.4f}\")\n",
    "    print(f\"{classifier.__class__.__name__} - Train Recall: {train_recall:.4f}, Test Recall: {test_recall:.4f}\")\n",
    "    print(f\"{classifier.__class__.__name__} - Train F1 Score: {train_f1:.4f}, Test F1 Score: {test_f1:.4f}\")\n",
    "    print(f\"{classifier.__class__.__name__} - Train Confusion Matrix:\\n{train_conf_matrix}\")\n",
    "    print(f\"{classifier.__class__.__name__} - Test Confusion Matrix:\\n{test_conf_matrix}\")\n",
    "\n",
    "    return best_model, best_params, train_accuracy, test_accuracy, train_conf_matrix, test_conf_matrix, train_precision, test_precision, train_recall, test_recall\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Logistic Regression Param Grid\n",
    "# lr_param_grid = (ParamGridBuilder()\n",
    "#                  .addGrid(lr.regParam, [0.1, 0.01])  # Regularization parameter\n",
    "#                  .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])  # ElasticNet parameter\n",
    "#                  .build())\n",
    "\n",
    "# # Random Forest Param Grid\n",
    "# rf_param_grid = (ParamGridBuilder()\n",
    "#                  .addGrid(rf.numTrees, [50, 100, 200])  # Number of trees\n",
    "#                  .addGrid(rf.maxDepth, [5, 10, 20])  # Max depth\n",
    "#                  .build())\n",
    "\n",
    "# # Multilayer Perceptron Param Grid\n",
    "# mlp_param_grid = (ParamGridBuilder()\n",
    "#                   .addGrid(mlp.maxIter, [100, 200])  # Number of iterations\n",
    "#                   .addGrid(mlp.layers, [[len(numeric_features), 10, 2], [len(numeric_features), 20, 2]])  # Layers structure\n",
    "#                   .build())\n",
    "\n",
    "# # Gradient Boosting Param Grid\n",
    "# gbt_param_grid = (ParamGridBuilder()\n",
    "#                   .addGrid(gbt.maxIter, [50, 100])  # Number of iterations\n",
    "#                   .addGrid(gbt.maxDepth, [5, 10])  # Max depth\n",
    "#                   .addGrid(gbt.stepSize, [0.05, 0.1])  # Step size (learning rate)\n",
    "#                   .build())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rhysw\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pyspark\\sql\\context.py:158: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 47602.0 failed 1 times, most recent failure: Lost task 0.0 in stage 47602.0 (TID 948415) (10.0.0.67 executor driver): org.apache.spark.SparkException: Python worker exited unexpectedly (crashed)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:612)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:594)\r\n\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:789)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\r\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\r\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\r\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\r\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\r\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\r\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\r\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\r\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\r\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\r\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\r\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\r\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\r\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\r\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\r\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\r\n\tat org.apache.spark.api.python.PythonRDD$.$anonfun$runJob$1(PythonRDD.scala:181)\r\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\r\n\tat java.base/java.lang.Thread.run(Thread.java:840)\r\nCaused by: java.io.EOFException\r\n\tat java.base/java.io.DataInputStream.readInt(DataInputStream.java:386)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:774)\r\n\t... 32 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2393)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2414)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2433)\r\n\tat org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:181)\r\n\tat org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:840)\r\nCaused by: org.apache.spark.SparkException: Python worker exited unexpectedly (crashed)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:612)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:594)\r\n\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:789)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\r\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\r\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\r\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\r\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\r\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\r\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\r\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\r\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\r\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\r\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\r\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\r\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\r\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\r\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\r\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\r\n\tat org.apache.spark.api.python.PythonRDD$.$anonfun$runJob$1(PythonRDD.scala:181)\r\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\r\n\t... 1 more\r\nCaused by: java.io.EOFException\r\n\tat java.base/java.io.DataInputStream.readInt(DataInputStream.java:386)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:774)\r\n\t... 32 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m evaluator \u001b[38;5;241m=\u001b[39m MulticlassClassificationEvaluator(labelCol\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m, predictionCol\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m, metricName\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Run cross-validation and hyperparameter tuning for GBT classifier\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m best_model, best_params, train_accuracy, test_accuracy, train_conf_matrix, test_conf_matrix, train_precision, test_precision, train_recall, test_recall \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate_and_evaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_transformed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_transformed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgbt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgbt_param_grid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluator\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Print all the metrics\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_model\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[7], line 40\u001b[0m, in \u001b[0;36mcross_validate_and_evaluate\u001b[1;34m(train_data, test_data, classifier, param_grid, evaluator, feature_col)\u001b[0m\n\u001b[0;32m     37\u001b[0m test_labels_and_preds \u001b[38;5;241m=\u001b[39m test_predictions\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mrdd\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Compute confusion matrix\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m train_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mMulticlassMetrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_labels_and_preds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m test_metrics \u001b[38;5;241m=\u001b[39m MulticlassMetrics(test_labels_and_preds)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Get confusion matrix\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pyspark\\mllib\\evaluation.py:288\u001b[0m, in \u001b[0;36mMulticlassMetrics.__init__\u001b[1;34m(self, predictionAndLabels)\u001b[0m\n\u001b[0;32m    286\u001b[0m sc \u001b[38;5;241m=\u001b[39m predictionAndLabels\u001b[38;5;241m.\u001b[39mctx\n\u001b[0;32m    287\u001b[0m sql_ctx \u001b[38;5;241m=\u001b[39m SQLContext\u001b[38;5;241m.\u001b[39mgetOrCreate(sc)\n\u001b[1;32m--> 288\u001b[0m numCol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43mpredictionAndLabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfirst\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    289\u001b[0m schema \u001b[38;5;241m=\u001b[39m StructType(\n\u001b[0;32m    290\u001b[0m     [\n\u001b[0;32m    291\u001b[0m         StructField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m, DoubleType(), nullable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m    292\u001b[0m         StructField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m, DoubleType(), nullable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m    293\u001b[0m     ]\n\u001b[0;32m    294\u001b[0m )\n\u001b[0;32m    295\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m numCol \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pyspark\\rdd.py:2888\u001b[0m, in \u001b[0;36mRDD.first\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2862\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfirst\u001b[39m(\u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRDD[T]\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m   2863\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2864\u001b[0m \u001b[38;5;124;03m    Return the first element in this RDD.\u001b[39;00m\n\u001b[0;32m   2865\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2886\u001b[0m \u001b[38;5;124;03m    ValueError: RDD is empty\u001b[39;00m\n\u001b[0;32m   2887\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2888\u001b[0m     rs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2889\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m rs:\n\u001b[0;32m   2890\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m rs[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pyspark\\rdd.py:2855\u001b[0m, in \u001b[0;36mRDD.take\u001b[1;34m(self, num)\u001b[0m\n\u001b[0;32m   2852\u001b[0m         taken \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   2854\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(partsScanned, \u001b[38;5;28mmin\u001b[39m(partsScanned \u001b[38;5;241m+\u001b[39m numPartsToTry, totalParts))\n\u001b[1;32m-> 2855\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunJob\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtakeUpToNumLeft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2857\u001b[0m items \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m res\n\u001b[0;32m   2858\u001b[0m partsScanned \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m numPartsToTry\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pyspark\\context.py:2510\u001b[0m, in \u001b[0;36mSparkContext.runJob\u001b[1;34m(self, rdd, partitionFunc, partitions, allowLocal)\u001b[0m\n\u001b[0;32m   2508\u001b[0m mappedRDD \u001b[38;5;241m=\u001b[39m rdd\u001b[38;5;241m.\u001b[39mmapPartitions(partitionFunc)\n\u001b[0;32m   2509\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 2510\u001b[0m sock_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPythonRDD\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunJob\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmappedRDD\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jrdd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartitions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2511\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_load_from_socket(sock_info, mappedRDD\u001b[38;5;241m.\u001b[39m_jrdd_deserializer))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pyspark\\errors\\exceptions\\captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 47602.0 failed 1 times, most recent failure: Lost task 0.0 in stage 47602.0 (TID 948415) (10.0.0.67 executor driver): org.apache.spark.SparkException: Python worker exited unexpectedly (crashed)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:612)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:594)\r\n\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:789)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\r\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\r\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\r\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\r\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\r\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\r\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\r\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\r\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\r\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\r\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\r\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\r\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\r\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\r\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\r\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\r\n\tat org.apache.spark.api.python.PythonRDD$.$anonfun$runJob$1(PythonRDD.scala:181)\r\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\r\n\tat java.base/java.lang.Thread.run(Thread.java:840)\r\nCaused by: java.io.EOFException\r\n\tat java.base/java.io.DataInputStream.readInt(DataInputStream.java:386)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:774)\r\n\t... 32 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2393)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2414)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2433)\r\n\tat org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:181)\r\n\tat org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:840)\r\nCaused by: org.apache.spark.SparkException: Python worker exited unexpectedly (crashed)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:612)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:594)\r\n\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:789)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\r\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\r\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\r\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\r\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\r\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\r\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\r\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\r\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\r\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\r\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\r\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\r\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\r\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\r\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\r\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\r\n\tat org.apache.spark.api.python.PythonRDD$.$anonfun$runJob$1(PythonRDD.scala:181)\r\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\r\n\t... 1 more\r\nCaused by: java.io.EOFException\r\n\tat java.base/java.io.DataInputStream.readInt(DataInputStream.java:386)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:774)\r\n\t... 32 more\r\n"
     ]
    }
   ],
   "source": [
    "# DIDNT RUN\n",
    "\n",
    "# # Add GradientBoosting Classifier\n",
    "# gbt = GBTClassifier()\n",
    "\n",
    "# # Gradient Boosting Param Grid\n",
    "# gbt_param_grid = (ParamGridBuilder()\n",
    "#                   .addGrid(gbt.maxIter, [50, 100])  # Number of iterations\n",
    "#                   .addGrid(gbt.maxDepth, [5, 10])  # Max depth\n",
    "#                   .addGrid(gbt.stepSize, [0.05, 0.1])  # Step size (learning rate)\n",
    "#                   .build())\n",
    "\n",
    "# # Define evaluator for accuracy\n",
    "# evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "# # Run cross-validation and hyperparameter tuning for GBT classifier\n",
    "# best_model, best_params, train_accuracy, test_accuracy, train_conf_matrix, test_conf_matrix, train_precision, test_precision, train_recall, test_recall = cross_validate_and_evaluate(\n",
    "#     train_transformed, test_transformed, gbt, gbt_param_grid, evaluator\n",
    "# )\n",
    "\n",
    "# # Print all the metrics\n",
    "# print(f\"Best Model: {best_model}\")\n",
    "# print(f\"Best Parameters: {best_params}\")\n",
    "# print(f\"Train Accuracy: {train_accuracy}\")\n",
    "# print(f\"Test Accuracy: {test_accuracy}\")\n",
    "# print(f\"Train Confusion Matrix:\\n{train_conf_matrix}\")\n",
    "# print(f\"Test Confusion Matrix:\\n{test_conf_matrix}\")\n",
    "# print(f\"Train Precision: {train_precision}\")\n",
    "# print(f\"Test Precision: {test_precision}\")\n",
    "# print(f\"Train Recall: {train_recall}\")\n",
    "# print(f\"Test Recall: {test_recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define evaluator for accuracy\n",
    "# evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # List of classifiers and their corresponding parameter grids\n",
    "# classifiers = [lr, rf, mlp, gbt]\n",
    "# param_grids = [lr_param_grid, rf_param_grid, mlp_param_grid, gbt_param_grid]\n",
    "\n",
    "# # Run cross-validation and hyperparameter tuning\n",
    "# best_models = cross_validate_and_evaluate(train_transformed, test_transformed, classifiers, param_grids, evaluator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See Features Importances for RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "# # Convert the feature importances to a DataFrame for better readability\n",
    "# importances = np.array(rf_model.featureImportances)\n",
    "# feature_importance_df = pd.DataFrame({\n",
    "#     'feature': numeric_features,\n",
    "#     'importance': importances\n",
    "# })\n",
    "\n",
    "# # Sort by importance\n",
    "# feature_importance_df = feature_importance_df.sort_values(by=\"importance\", ascending=False)\n",
    "# print(feature_importance_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vmN39GastBtO"
   },
   "source": [
    "## Adjust threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369
    },
    "executionInfo": {
     "elapsed": 136,
     "status": "error",
     "timestamp": 1733853610412,
     "user": {
      "displayName": "Rhys Wickens",
      "userId": "08020993139237173533"
     },
     "user_tz": 420
    },
    "id": "x__NcgmbtDuJ",
    "outputId": "9a5e7855-4039-45be-f8e3-c0d857f0e5dc"
   },
   "outputs": [],
   "source": [
    "# from pyspark.sql.functions import col, when\n",
    "\n",
    "# # Define a new decision threshold\n",
    "# threshold = 0.3  # Lowering the threshold increases recall at the potential cost of precision\n",
    "\n",
    "# # Adjust the decision threshold for Logistic Regression predictions\n",
    "# lr_test_predictions = predictions[\"LogisticRegression\"][\"test\"]\n",
    "# lr_test_predictions_with_threshold = lr_test_predictions.withColumn(\n",
    "#     \"adjusted_prediction\",\n",
    "#     when(col(\"probability\").getItem(1) > threshold, 1).otherwise(0)  # Positive class is at index 1\n",
    "# )\n",
    "\n",
    "# # Compute metrics with the adjusted threshold\n",
    "# print(\"Metrics for Logistic Regression with Adjusted Threshold on Test Data:\")\n",
    "# compute_metrics(lr_test_predictions_with_threshold, label_col=\"label\", prediction_col=\"adjusted_prediction\")\n",
    "\n",
    "# # Repeat for train data\n",
    "# lr_train_predictions = predictions[\"LogisticRegression\"][\"train\"]\n",
    "# lr_train_predictions_with_threshold = lr_train_predictions.withColumn(\n",
    "#     \"adjusted_prediction\",\n",
    "#     when(col(\"probability\").getItem(1) > threshold, 1).otherwise(0)\n",
    "# )\n",
    "\n",
    "# # Compute metrics for the train data\n",
    "# print(\"Metrics for Logistic Regression with Adjusted Threshold on Train Data:\")\n",
    "# compute_metrics(lr_train_predictions_with_threshold, label_col=\"label\", prediction_col=\"adjusted_prediction\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RXekt-YwuH9u"
   },
   "source": [
    "## Hyperparameter tuning using CrossValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qLhjRdLXuDIj"
   },
   "outputs": [],
   "source": [
    "# from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "# # Define parameter grid for Logistic Regression\n",
    "# paramGrid = ParamGridBuilder() \\\n",
    "#     .addGrid(lr.regParam, [0.01, 0.1, 1.0]) \\\n",
    "#     .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0]) \\\n",
    "#     .build()\n",
    "\n",
    "# # CrossValidator\n",
    "# crossval = CrossValidator(\n",
    "#     estimator=Pipeline(stages=[lr]),\n",
    "#     estimatorParamMaps=paramGrid,\n",
    "#     evaluator=MulticlassClassificationEvaluator(metricName=\"accuracy\"),\n",
    "#     numFolds=3\n",
    "# )\n",
    "\n",
    "# # Fit cross-validation model\n",
    "# cv_model = crossval.fit(train_transformed)\n",
    "\n",
    "# # Get the best model\n",
    "# best_lr_model = cv_model.bestModel\n",
    "\n",
    "# # Evaluate the best model on the test data\n",
    "# best_lr_test_predictions = best_lr_model.transform(test_transformed)\n",
    "# print(\"Metrics for Best Logistic Regression Model from CrossValidator on Test Data:\")\n",
    "# compute_metrics(best_lr_test_predictions, label_col=\"label\", prediction_col=\"prediction\")\n",
    "\n",
    "# # Evaluate the best model on the train data\n",
    "# best_lr_train_predictions = best_lr_model.transform(train_transformed)\n",
    "# print(\"Metrics for Best Logistic Regression Model from CrossValidator on Train Data:\")\n",
    "# compute_metrics(best_lr_train_predictions, label_col=\"label\", prediction_col=\"prediction\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "https://github.com/612Project/612Project/blob/dev/AirlineDelays.ipynb",
     "timestamp": 1733357666735
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
